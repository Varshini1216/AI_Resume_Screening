{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3242b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48350987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\varsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\varsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6181260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>HR SPECIALIST       Summary    Dedica...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>HR MANAGER         Skill Highlights  ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                         Resume_str  \\\n",
       "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...   \n",
       "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
       "2  33176873           HR DIRECTOR       Summary      Over 2...   \n",
       "3  27018550           HR SPECIALIST       Summary    Dedica...   \n",
       "4  17812897           HR MANAGER         Skill Highlights  ...   \n",
       "\n",
       "                                         Resume_html Category  \n",
       "0  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "1  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "2  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "3  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
       "4  <div class=\"fontsize fontface vmargins hmargin...       HR  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_df = pd.read_csv(\"../data/Resume.csv\")\n",
    "job_df = pd.read_csv(\"../data/DataScientist.csv\")\n",
    "\n",
    "resume_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f13f01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2fac062",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df['clean_resume'] = resume_df.iloc[:, 0].apply(clean_text)\n",
    "job_df['clean_jd'] = job_df.iloc[:, 0].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef6f19cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_list = [\n",
    "    'python','sql','machine learning','deep learning',\n",
    "    'nlp','data analysis','data visualization',\n",
    "    'tensorflow','pandas','numpy','scikit learn'\n",
    "]\n",
    "\n",
    "def extract_skills(text):\n",
    "    return list(set([skill for skill in skills_list if skill in text]))\n",
    "\n",
    "resume_df['skills'] = resume_df['clean_resume'].apply(extract_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d90a9019",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text_col = resume_df.columns[0]\n",
    "job_text_col = job_df.columns[0]\n",
    "\n",
    "resume_df['clean_resume'] = resume_df[resume_text_col].astype(str).apply(clean_text)\n",
    "job_df['clean_jd'] = job_df[job_text_col].astype(str).apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6762aa53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \n",
       "1    \n",
       "2    \n",
       "3    \n",
       "4    \n",
       "5    \n",
       "6    \n",
       "7    \n",
       "8    \n",
       "9    \n",
       "Name: clean_resume, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_df['clean_resume'].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0be4aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty resumes: 2484\n",
      "Empty job descriptions: 3909\n"
     ]
    }
   ],
   "source": [
    "print(\"Empty resumes:\", (resume_df['clean_resume'].str.strip() == \"\").sum())\n",
    "print(\"Empty job descriptions:\", (job_df['clean_jd'].str.strip() == \"\").sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3357ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df = resume_df[resume_df['clean_resume'].str.strip() != \"\"]\n",
    "job_df = job_df[job_df['clean_jd'].str.strip() != \"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8310fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_text = resume_df['clean_resume'].tolist() + job_df['clean_jd'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbffe0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "      <th>clean_resume</th>\n",
       "      <th>skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, Resume_str, Resume_html, Category, clean_resume, skills]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59c2b8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Competitors</th>\n",
       "      <th>Easy Apply</th>\n",
       "      <th>clean_jd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, index, Job Title, Salary Estimate, Job Description, Rating, Company Name, Location, Headquarters, Size, Founded, Type of ownership, Industry, Sector, Revenue, Competitors, Easy Apply, clean_jd]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "611c127a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: clean_jd, dtype: object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df['clean_jd'].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8e2e8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df = resume_df[resume_df['clean_resume'].str.len() > 3]\n",
    "job_df = job_df[job_df['clean_jd'].str.len() > 3]\n",
    "\n",
    "resume_df.reset_index(drop=True, inplace=True)\n",
    "job_df.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb56f747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume shape: (0, 6)\n",
      "Job shape: (0, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Resume shape:\", resume_df.shape)\n",
    "print(\"Job shape:\", job_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b60be6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume columns: Index(['ID', 'Resume_str', 'Resume_html', 'Category', 'clean_resume',\n",
      "       'skills'],\n",
      "      dtype='object')\n",
      "Job columns: Index(['Unnamed: 0', 'index', 'Job Title', 'Salary Estimate',\n",
      "       'Job Description', 'Rating', 'Company Name', 'Location', 'Headquarters',\n",
      "       'Size', 'Founded', 'Type of ownership', 'Industry', 'Sector', 'Revenue',\n",
      "       'Competitors', 'Easy Apply', 'clean_jd'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Resume columns:\", resume_df.columns)\n",
    "print(\"Job columns:\", job_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf48da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE column names if needed\n",
    "resume_text_column = resume_df.columns[-1]\n",
    "job_text_column = job_df.columns[-1]\n",
    "\n",
    "resume_df['clean_resume'] = resume_df[resume_text_column].astype(str).apply(clean_text)\n",
    "job_df['clean_jd'] = job_df[job_text_column].astype(str).apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2aa49d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: clean_resume, dtype: object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_df['clean_resume'].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7e44877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: clean_jd, dtype: object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df['clean_jd'].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcf8d20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Competitors</th>\n",
       "      <th>Easy Apply</th>\n",
       "      <th>clean_jd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, index, Job Title, Salary Estimate, Job Description, Rating, Company Name, Location, Headquarters, Size, Founded, Type of ownership, Industry, Sector, Revenue, Competitors, Easy Apply, clean_jd]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8201d0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Data columns (total 18 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Unnamed: 0         0 non-null      int64  \n",
      " 1   index              0 non-null      int64  \n",
      " 2   Job Title          0 non-null      object \n",
      " 3   Salary Estimate    0 non-null      object \n",
      " 4   Job Description    0 non-null      object \n",
      " 5   Rating             0 non-null      float64\n",
      " 6   Company Name       0 non-null      object \n",
      " 7   Location           0 non-null      object \n",
      " 8   Headquarters       0 non-null      object \n",
      " 9   Size               0 non-null      object \n",
      " 10  Founded            0 non-null      int64  \n",
      " 11  Type of ownership  0 non-null      object \n",
      " 12  Industry           0 non-null      object \n",
      " 13  Sector             0 non-null      object \n",
      " 14  Revenue            0 non-null      object \n",
      " 15  Competitors        0 non-null      object \n",
      " 16  Easy Apply         0 non-null      object \n",
      " 17  clean_jd           0 non-null      object \n",
      "dtypes: float64(1), int64(3), object(14)\n",
      "memory usage: 132.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "job_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3038f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'index', 'Job Title', 'Salary Estimate',\n",
      "       'Job Description', 'Rating', 'Company Name', 'Location', 'Headquarters',\n",
      "       'Size', 'Founded', 'Type of ownership', 'Industry', 'Sector', 'Revenue',\n",
      "       'Competitors', 'Easy Apply', 'clean_jd'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(job_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "587ccca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df.drop(columns=['clean_jd'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f923fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df['clean_jd'] = job_df['Job Description'].astype(str).apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed30099b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Description</th>\n",
       "      <th>clean_jd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Job Description, clean_jd]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df[['Job Description', 'clean_jd']].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f9dd9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n', ' ', text)          # keep line breaks safe\n",
    "    text = re.sub(r'[^a-zA-Z ]', ' ', text)  # remove symbols\n",
    "    text = re.sub(r'\\s+', ' ', text)         # normalize spaces\n",
    "    \n",
    "    words = text.split()\n",
    "    \n",
    "    # ⚠️ IMPORTANT: do NOT remove all stopwords\n",
    "    words = [\n",
    "        lemmatizer.lemmatize(w)\n",
    "        for w in words\n",
    "        if len(w) > 2\n",
    "    ]\n",
    "    \n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f93cb7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df['clean_jd'] = job_df['Job Description'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5cf5522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Empty DataFrame\\nColumns: [Job Description, clean_jd]\\nIndex: []'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df[['Job Description', 'clean_jd']].head(3).to_string()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "227ce2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = pd.read_csv(\"../data/DataScientist.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e401872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "resume_df = pd.read_csv(\"../data/Resume.csv\")\n",
    "job_df = pd.read_csv(\"../data/DataScientist.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0c5305f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\varsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    words = [lemmatizer.lemmatize(w) for w in text.split() if len(w) > 2]\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6438720e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df['clean_resume'] = resume_df['Resume_str'].apply(clean_text)\n",
    "job_df['clean_jd'] = job_df['Job Description'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4da5dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Resume_str                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     clean_resume\\n0                                                                                                                                                               HR ADMINISTRATOR/MARKETING ASSOCIATE\\\\n\\\\nHR ADMINISTRATOR       Summary     Dedicated Customer Service Manager with 15+ years of experience in Hospitality and Customer Service Management.   Respected builder and leader of customer-focused teams; strives to instill a shared, enthusiastic commitment to customer service.         Highlights         Focused on customer satisfaction  Team management  Marketing savvy  Conflict resolution techniques     Training and development  Skilled multi-tasker  Client relations specialist           Accomplishments      Missouri DOT Supervisor Training Certification  Certified by IHG in Customer Loyalty and Marketing by Segment   Hilton Worldwide General Manager Training Certification  Accomplished Trainer for cross server hospitality systems such as    Hilton OnQ  ,   Micros    Opera PMS   , Fidelio    OPERA    Reservation System (ORS) ,   Holidex    Completed courses and seminars in customer service, sales strategies, inventory control, loss prevention, safety, time management, leadership and performance assessment.        Experience      HR Administrator/Marketing Associate\\\\n\\\\nHR Administrator     Dec 2013   to   Current      Company Name   －   City  ,   State     Helps to develop policies, directs and coordinates activities such as employment, compensation, labor relations, benefits, training, and employee services.  Prepares employee separation notices and related documentation  Keeps records of benefits plans participation such as insurance and pension plan, personnel transactions such as hires, promotions, transfers, performance reviews, and terminations, and employee statistics for government reporting.  Advises management in appropriate resolution of employee relations issues.  Administers benefits programs such as life, health, dental, insurance, pension plans, vacation, sick leave, leave of absence, and employee assistance.     Marketing Associate \\xa0   Designed and created marketing collateral for sales meetings, trade shows and company executives.  Managed the in-house advertising program consisting of print and media collateral pieces.  Assisted in the complete design and launch of the company's website in 2 months.  Created an official company page on Facebook to facilitate interaction with customers.  Analyzed ratings and programming features of competitors to evaluate the effectiveness of marketing strategies.         Advanced Medical Claims Analyst     Mar 2012   to   Dec 2013      Company Name   －   City  ,   State     Reviewed medical bills for the accuracy of the treatments, tests, and hospital stays prior to sanctioning the claims.  Trained to interpret the codes (ICD-9, CPT) and terminology commonly used in medical billing to fully understand the paperwork that is submitted by healthcare providers.  Required to have organizational and analytical skills as well as computer skills, knowledge of medical terminology and procedures, statistics, billing standards, data analysis and laws regarding medical billing.         Assistant General Manager     Jun 2010   to   Dec 2010      Company Name   －   City  ,   State     Performed duties including but not limited to, budgeting and financial management, accounting, human resources, payroll and purchasing.  Established and maintained close working relationships with all departments of the hotel to ensure maximum operation, productivity, morale and guest service.  Handled daily operations and reported directly to the corporate office.  Hired and trained staff on overall objectives and goals with an emphasis on high customer service.  Marketing and Advertising, working on public relations with the media, government and local businesses and Chamber of Commerce.         Executive Support / Marketing Assistant     Jul 2007   to   Jun 2010      Company Name   －   City  ,   State     Provided assistance to various department heads - Executive, Marketing, Customer Service, Human Resources.  Managed front-end operations to ensure friendly and efficient transactions.  Ensured the swift resolution of customer issues to preserve customer loyalty while complying with company policies.  Exemplified the second-to-none customer service delivery in all interactions with customers and potential clients.         Reservation & Front Office Manager     Jun 2004   to   Jul 2007      Company Name   －   City  ,   State          Owner/ Partner     Dec 2001   to   May 2004      Company Name   －   City  ,   State          Price Integrity Coordinator     Aug 1999   to   Dec 2001      Company Name   －   City  ,   State          Education      N/A  ,   Business Administration   1999     Jefferson College   －   City  ,   State       Business Administration  Marketing / Advertising         High School Diploma  ,   College Prep. studies   1998     Sainte Genevieve Senior High   －   City  ,   State       Awarded American Shrubel Leadership Scholarship to Jefferson College         Skills     Accounting, ads, advertising, analytical skills, benefits, billing, budgeting, clients, Customer Service, data analysis, delivery, documentation, employee relations, financial management, government relations, Human Resources, insurance, labor relations, layout, Marketing, marketing collateral, medical billing, medical terminology, office, organizational, payroll, performance reviews, personnel, policies, posters, presentations, public relations, purchasing, reporting, statistics, website.                                                                                                                                                          administrator marketing associate administrator summary dedicated customer service manager with year experience hospitality and customer service management respected builder and leader customer focused team strives instill shared enthusiastic commitment customer service highlight focused customer satisfaction team management marketing savvy conflict resolution technique training and development skilled multi tasker client relation specialist accomplishment missouri dot supervisor training certification certified ihg customer loyalty and marketing segment hilton worldwide general manager training certification accomplished trainer for cross server hospitality system such hilton onq micros opera pm fidelio opera reservation system or holidex completed course and seminar customer service sale strategy inventory control loss prevention safety time management leadership and performance assessment experience administrator marketing associate administrator dec current company name city state help develop policy directs and coordinate activity such employment compensation labor relation benefit training and employee service prepares employee separation notice and related documentation keep record benefit plan participation such insurance and pension plan personnel transaction such hire promotion transfer performance review and termination and employee statistic for government reporting advises management appropriate resolution employee relation issue administers benefit program such life health dental insurance pension plan vacation sick leave leave absence and employee assistance marketing associate designed and created marketing collateral for sale meeting trade show and company executive managed the house advertising program consisting print and medium collateral piece assisted the complete design and launch the company website month created official company page facebook facilitate interaction with customer analyzed rating and programming feature competitor evaluate the effectiveness marketing strategy advanced medical claim analyst mar dec company name city state reviewed medical bill for the accuracy the treatment test and hospital stay prior sanctioning the claim trained interpret the code icd cpt and terminology commonly used medical billing fully understand the paperwork that submitted healthcare provider required have organizational and analytical skill well computer skill knowledge medical terminology and procedure statistic billing standard data analysis and law regarding medical billing assistant general manager jun dec company name city state performed duty including but not limited budgeting and financial management accounting human resource payroll and purchasing established and maintained close working relationship with all department the hotel ensure maximum operation productivity morale and guest service handled daily operation and reported directly the corporate office hired and trained staff overall objective and goal with emphasis high customer service marketing and advertising working public relation with the medium government and local business and chamber commerce executive support marketing assistant jul jun company name city state provided assistance various department head executive marketing customer service human resource managed front end operation ensure friendly and efficient transaction ensured the swift resolution customer issue preserve customer loyalty while complying with company policy exemplified the second none customer service delivery all interaction with customer and potential client reservation front office manager jun jul company name city state owner partner dec may company name city state price integrity coordinator aug dec company name city state education business administration jefferson college city state business administration marketing advertising high school diploma college prep study sainte genevieve senior high city state awarded american shrubel leadership scholarship jefferson college skill accounting ad advertising analytical skill benefit billing budgeting client customer service data analysis delivery documentation employee relation financial management government relation human resource insurance labor relation layout marketing marketing collateral medical billing medical terminology office organizational payroll performance review personnel policy poster presentation public relation purchasing reporting statistic website\\n1           HR SPECIALIST, US HR OPERATIONS       Summary     Versatile  media professional with background in Communications, Marketing, Human Resources and Technology.\\xa0        Experience     09/2015   to   Current     HR Specialist, US HR Operations    Company Name   －   City  ,   State       Managed communication regarding launch of Operations group, policy changes and system outages      Designed standard work and job aids to create comprehensive training program for new employees and contractors         Audited job postings for old, pending, on-hold and draft positions.           Audited union hourly, non-union hourly and salary background checks and drug screens             Conducted monthly new hire benefits briefing to new employees across all business units               Served as a link between HR Managers and vendors by handling questions and resolving system-related issues         Provide real-time process improvement feedback on key metrics and initiatives  Successfully re-branded US HR Operations SharePoint site  Business Unit project manager for RFI/RFP on Background Check and Drug Screen vendor         01/2014   to   05/2015     IT, Marketing and Communications Co-op    Company Name   －   City  ,   State      Posted new articles, changes and updates to corporate SharePoint site including graphics and visual communications.  Researched and drafted articles and feature stories to promote company activities and programs.  Co-edited and developed content for quarterly published newsletter.  Provided communication support for internal and external events.  Collaborated with Communication team, media professionals and vendors to determine program needs for print materials, web design and digital communications.  Entrusted to lead product, service and software launches for Digital Asset Management tool, Marketing Toolkit website and Executive Tradeshows Calendar.  Created presentations for management and executive approval to ensure alignment with corporate guidelines and branding.  Maintained the MySikorsky SharePoint site and provided timely solutions to mitigate issues.\\xa0\\xa0\\xa0\\xa0  Created story board and produced video for annual IT All Hands meeting.         10/2012   to   01/2014     Relationship Coordinator/Marketing Specialist    Company Name   －   City  ,   State       Partnered with vendor to manage the in-house advertising program consisting of print and media collateral pieces.     Coordinated pre-show and post-show activities at trade shows.     Managed marketing campaigns to generate new business and to support partner and sales teams.     Ordered marketing collateral for meetings, trade shows and advisors.    Improved, administered and modified marketing programs to increase product awareness.  Assisted in preparing internal promotional publications, managed marketing material inventory and supervised distribution of publications to ensure high quality product output.  Coordinated marketing materials including brochures, promotional materials and products.  Partnered with graphic designers to develop appropriate materials and branding for brochures.  Used tracking and reporting systems for sales leads and appointments.         09/2009   to   10/2012     Assistant Head Teller    Company Name   －   City  ,   State       Received an internal audit score of  100 %.     Performed daily and monthly audits of ATM machines and tellers.     Educated customers on a variety of retail products and available credit options.       Consistently met or exceeded quarterly sales goals     Promoted products and services to\\\\ncustomers while maintaining company brand identity\\\\n\\\\n·\\xa0\\xa0\\xa0\\xa0\\\\n  Implemented programs to achieve\\\\nand exceed customer and company participation goals\\xa0\\\\n\\\\n\\xa0  Organized company sponsored events on campus resulting in increased\\\\nbrand awareness\\\\n\\\\n·\\xa0\\xa0\\xa0\\xa0\\\\n  Coached peers on\\\\nthe proper use of programs to improve work flow efficiency  Utilized product knowledge to successfully sell\\\\nto and refer clients based on individual needs  Promoted marketing the grand opening\\\\nof new branch locations to strengthen company brand affinity\\\\n\\\\n·\\xa0\\xa0\\xa0\\xa0   Organized company sponsored events\\\\nresulting in increased brand awareness and improved sales\\\\n\\\\n·\\xa0\\xa0\\xa0\\xa0   Coached peers on the proper use of\\\\nprograms to increase work flow efficiency\\\\n\\\\n          Senior Producer - 2014 SHU Media Exchange    Company Name   －   City  ,   State      Planned and executed event\\xa0focusing on Connecticut's creative corridor, growth of industry and opportunities that come with development. A\\xa0 panel of industry professionals addressed topics related to media and hosted a question and answer session for approximately 110 attendees. Following the forum, guests were invited to engage in networking and conversation at a post-event reception.         Education     2014     Master of Arts  :   Corporate Communication & Public Relations    Sacred Heart University   －   City  ,   State             2013     Bachelor of Arts  :   Relational Communication    Western Connecticut State University   －   City  ,   State              Skills    Adobe Photoshop, ADP, Asset Management, branding, brochures, content, Customer Care, Final Cut Pro, graphics, graphic, HR, Illustrator, InDesign, Innovation, inventory, Lotus Notes, marketing, marketing materials, marketing material, materials, Microsoft Office, SharePoint, newsletter, presentations, process improvement, Project Management, promotional materials, publications, Quality, real-time, Recruitment, reporting, RFP, sales, stories, Employee Development, video, web design, website, articles     specialist operation summary versatile medium professional with background communication marketing human resource and technology experience current specialist operation company name city state managed communication regarding launch operation group policy change and system outage designed standard work and job aid create comprehensive training program for new employee and contractor audited job posting for old pending hold and draft position audited union hourly non union hourly and salary background check and drug screen conducted monthly new hire benefit briefing new employee across all business unit served link between manager and vendor handling question and resolving system related issue provide real time process improvement feedback key metric and initiative successfully branded operation sharepoint site business unit project manager for rfi rfp background check and drug screen vendor marketing and communication company name city state posted new article change and update corporate sharepoint site including graphic and visual communication researched and drafted article and feature story promote company activity and program edited and developed content for quarterly published newsletter provided communication support for internal and external event collaborated with communication team medium professional and vendor determine program need for print material web design and digital communication entrusted lead product service and software launch for digital asset management tool marketing toolkit website and executive tradeshows calendar created presentation for management and executive approval ensure alignment with corporate guideline and branding maintained the mysikorsky sharepoint site and provided timely solution mitigate issue created story board and produced video for annual all hand meeting relationship coordinator marketing specialist company name city state partnered with vendor manage the house advertising program consisting print and medium collateral piece coordinated pre show and post show activity trade show managed marketing campaign generate new business and support partner and sale team ordered marketing collateral for meeting trade show and advisor improved administered and modified marketing program increase product awareness assisted preparing internal promotional publication managed marketing material inventory and supervised distribution publication ensure high quality product output coordinated marketing material including brochure promotional material and product partnered with graphic designer develop appropriate material and branding for brochure used tracking and reporting system for sale lead and appointment assistant head teller company name city state received internal audit score performed daily and monthly audit atm machine and teller educated customer variety retail product and available credit option consistently met exceeded quarterly sale goal promoted product and service customer while maintaining company brand identity implemented program achieve and exceed customer and company participation goal organized company sponsored event campus resulting increased brand awareness coached peer the proper use program improve work flow efficiency utilized product knowledge successfully sell and refer client based individual need promoted marketing the grand opening new branch location strengthen company brand affinity organized company sponsored event resulting increased brand awareness and improved sale coached peer the proper use program increase work flow efficiency senior producer shu medium exchange company name city state planned and executed event focusing connecticut creative corridor growth industry and opportunity that come with development panel industry professional addressed topic related medium and hosted question and answer session for approximately attendee following the forum guest were invited engage networking and conversation post event reception education master art corporate communication public relation sacred heart university city state bachelor art relational communication western connecticut state university city state skill adobe photoshop adp asset management branding brochure content customer care final cut pro graphic graphic illustrator indesign innovation inventory lotus note marketing marketing material marketing material material microsoft office sharepoint newsletter presentation process improvement project management promotional material publication quality real time recruitment reporting rfp sale story employee development video web design website article\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_df[['Resume_str', 'clean_resume']].head(2).to_string()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e73b144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Job Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              clean_jd\\n0  ABOUT HOPPER\\\\n\\\\nAt Hopper, we’re on a mission to make booking travel faster, easier, and more transparent. We are leveraging the power that comes from combining massive amounts of data and machine learning to build the world’s fastest-growing travel app -- one that enables our customers to save money and travel more. With over $235M CAD in funding from leading investors in both Canada and the US, Hopper is primed to continue its path toward becoming the go-to way to book travel as the world continues its shift to mobile.\\\\n\\\\nRecognized as the fastest-growing travel app by Forbes and one of the world’s most innovative companies by Fast Company two years in a row, Hopper has been downloaded over 40 million times and has helped travelers plan over 100 million trips and counting. The app has received high praise in the form of mobile accolades such as the Webby Award for Best Travel App of 2019, the Google Play Award for Standout Startup of 2016 and Apple’s App Store Best of 2015.\\\\n\\\\nTake off with us!\\\\n\\\\nTHE ROLE\\\\n\\\\nHopper is looking for a data-savvy individual to join our team as a Data Scientist and lead data-centric product development and complex business intelligence projects within our core air travel business unit. Every day you would draw powerful insights from our real-time feed of billions of flight search results and archives of several trillion data points. To succeed at Hopper you need the talent, passion, and experience to thrive in a highly performing company.\\\\nIN THIS ROLE YOU WILL:\\\\nFrame and conduct complex exploratory analyses needed to deepen our understanding of Hopper users.\\\\nPartner with product, business and strategy teams to leverage this user understanding for product improvements and other initiatives\\\\nUse machine learning and big data tools on tremendously large and complex data sets to enhance our data-driven, personalized travel advice\\\\nConduct research into various aspects of our business and employ statistical and modeling techniques when appropriate to make recommendations to non-technical stakeholders\\\\nCreate advanced dashboards for product experiment tracking and business unit performance analysis using Amplitude and Tableau\\\\nFind effective ways to simplify and communicate analyses to a non-technical audience.\\\\nA PERFECT CANDIDATE HAS:\\\\nA degree in Math, Statistics, Computer Science, Engineering or other quantitative disciplines\\\\nExtremely strong analytical and problem-solving skills\\\\nProven ability to communicate complex technical work to a non-technical audience\\\\nA strong passion for and extensive experience in conducting empirical research and answering hard questions with data\\\\nExperience with a data visualization tool (Tableau preferred) and project analysis tool such as Amplitude\\\\nExperience with relational databases and SQL, especially Hive\\\\nExperience working with extremely large data sets\\\\nExperience in Pandas, R, SAS or other tools appropriate for large scale data preparation and analysis\\\\nExperience with data mining, machine learning, statistical modeling tools and underlying algorithms\\\\nProficiency with Unix/Linux environments\\\\nBENEFITS\\\\n\\\\n• Well-funded and proven startup with large ambitions, competitive salary and stock options\\\\n• Dynamic and entrepreneurial team where pushing limits is everyday business\\\\n• 100% employer paid medical, dental, vision, disability and life insurance plans\\\\n• Access to a 401k (US) or Retirement Savings Plan (Canada)  about hopper hopper mission make booking travel faster easier and more transparent are leveraging the power that come from combining massive amount data and machine learning build the world fastest growing travel app one that enables our customer save money and travel more with over cad funding from leading investor both canada and the hopper primed continue it path toward becoming the way book travel the world continues it shift mobile recognized the fastest growing travel app forbes and one the world most innovative company fast company two year row hopper ha been downloaded over million time and ha helped traveler plan over million trip and counting the app ha received high praise the form mobile accolade such the webby award for best travel app the google play award for standout startup and apple app store best take off with the role hopper looking for data savvy individual join our team data scientist and lead data centric product development and complex business intelligence project within our core air travel business unit every day you would draw powerful insight from our real time feed billion flight search result and archive several trillion data point succeed hopper you need the talent passion and experience thrive highly performing company this role you will frame and conduct complex exploratory analysis needed deepen our understanding hopper user partner with product business and strategy team leverage this user understanding for product improvement and other initiative use machine learning and big data tool tremendously large and complex data set enhance our data driven personalized travel advice conduct research into various aspect our business and employ statistical and modeling technique when appropriate make recommendation non technical stakeholder create advanced dashboard for product experiment tracking and business unit performance analysis using amplitude and tableau find effective way simplify and communicate analysis non technical audience perfect candidate ha degree math statistic computer science engineering other quantitative discipline extremely strong analytical and problem solving skill proven ability communicate complex technical work non technical audience strong passion for and extensive experience conducting empirical research and answering hard question with data experience with data visualization tool tableau preferred and project analysis tool such amplitude experience with relational database and sql especially hive experience working with extremely large data set experience panda sa other tool appropriate for large scale data preparation and analysis experience with data mining machine learning statistical modeling tool and underlying algorithm proficiency with unix linux environment benefit well funded and proven startup with large ambition competitive salary and stock option dynamic and entrepreneurial team where pushing limit everyday business employer paid medical dental vision disability and life insurance plan access retirement saving plan canada\\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              At Noom, we use scientifically proven methods to help our users create healthier lifestyles, and manage important conditions like Type-II Diabetes, Obesity, and Hypertension. Our Engineering team is at the forefront of this challenge, solving complex technical and UX problems on our mobile apps that center around habits, behavior, and lifestyle.\\\\n\\\\nWe are looking for a Data Scientist to join our Data team and help us ensure that we apply the best approaches to data analysis and research, artificial intelligence, and machine learning.\\\\n\\\\nWhat You\\'ll Like About Us:\\\\nWe work on problems that affect the lives of real people. Our users depend on us to make positive changes to their health and their lives.\\\\nWe base our work on scientifically-proven, peer-reviewed methodologies that are designed by medical professionals.\\\\nWe are a data-driven company through and through.\\\\nWe\\'re a respectful, diverse, and dynamic environment in which Engineering is a first-class citizen, and where you\\'ll be able to work on a variety of interesting problems that affect the lives of real people.\\\\nWe offer a generous budget for personal development expenses like training courses, conferences, and books.\\\\nYou\\'ll get three weeks\\' paid vacation and a flexible work policy that is remote- and family-friendly (about 50% of our engineering team is fully remote). We worry about results, not time spent in seats.\\\\nWhat We\\'ll Like About You:\\\\nYou have 4+ years of experience as a Data Scientist or Data Analyst in a similarly-sized organization, with a proven record of analysis and research that positively impacts your team.\\\\nYou possess excellent communication skills and the ability to clearly communicate technical concepts to a non-technical audience\\\\nYou possess excellent SQL/relational algebra skills, ideally with at least a basic knowledge of how different types of databases (e.g.: column vs row storage) work.\\\\nYou have a superior knowledge of statistical analysis methods, such as input selection, logistic and standard regression, etc.\\\\nYou are comfortable writing Python code, and have good working knowledge of pandas and numpy. We don\\'t expect you to write production-quality code, but you should have some programming experience.\\\\nYou are comfortable with at least \"medium data\" technologies and how to transcend the \"memory bound\" nature of most analytics tools.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               noom use scientifically proven method help our user create healthier lifestyle and manage important condition like type diabetes obesity and hypertension our engineering team the forefront this challenge solving complex technical and problem our mobile apps that center around habit behavior and lifestyle are looking for data scientist join our data team and help ensure that apply the best approach data analysis and research artificial intelligence and machine learning what you like about work problem that affect the life real people our user depend make positive change their health and their life base our work scientifically proven peer reviewed methodology that are designed medical professional are data driven company through and through respectful diverse and dynamic environment which engineering first class citizen and where you able work variety interesting problem that affect the life real people offer generous budget for personal development expense like training course conference and book you get three week paid vacation and flexible work policy that remote and family friendly about our engineering team fully remote worry about result not time spent seat what like about you you have year experience data scientist data analyst similarly sized organization with proven record analysis and research that positively impact your team you possess excellent communication skill and the ability clearly communicate technical concept non technical audience you possess excellent sql relational algebra skill ideally with least basic knowledge how different type database column row storage work you have superior knowledge statistical analysis method such input selection logistic and standard regression etc you are comfortable writing python code and have good working knowledge panda and numpy don expect you write production quality code but you should have some programming experience you are comfortable with least medium data technology and how transcend the memory bound nature most analytics tool'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df[['Job Description', 'clean_jd']].head(2).to_string()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fc6d7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Resume_str', 'Resume_html', 'Category', 'clean_resume'], dtype='object')\n",
      "Index(['Unnamed: 0', 'index', 'Job Title', 'Salary Estimate',\n",
      "       'Job Description', 'Rating', 'Company Name', 'Location', 'Headquarters',\n",
      "       'Size', 'Founded', 'Type of ownership', 'Industry', 'Sector', 'Revenue',\n",
      "       'Competitors', 'Easy Apply', 'clean_jd'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(resume_df.columns)\n",
    "print(job_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a446f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     2484.000000\n",
       "mean      5272.511675\n",
       "std       2387.353099\n",
       "min          0.000000\n",
       "25%       4289.750000\n",
       "50%       4910.500000\n",
       "75%       6098.750000\n",
       "max      31222.000000\n",
       "Name: clean_resume, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_df['clean_resume'].str.len().describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26a30478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume rows: (2484, 5)\n",
      "Job rows: (3909, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Resume rows:\", resume_df.shape)\n",
    "print(\"Job rows:\", job_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b235dc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     3909.000000\n",
       "mean      3168.457150\n",
       "std       1782.303135\n",
       "min         41.000000\n",
       "25%       1880.000000\n",
       "50%       2935.000000\n",
       "75%       4150.000000\n",
       "max      17496.000000\n",
       "Name: clean_jd, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df['clean_jd'].str.len().describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10af7b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 6393\n"
     ]
    }
   ],
   "source": [
    "combined_text = (\n",
    "    resume_df['clean_resume'].astype(str).tolist() +\n",
    "    job_df['clean_jd'].astype(str).tolist()\n",
    ")\n",
    "\n",
    "print(\"Total documents:\", len(combined_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c317fa14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6393, 5000)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    max_features=5000\n",
    ")\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(combined_text)\n",
    "tfidf_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c91ea54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_vectors = tfidf_matrix[:len(resume_df)]\n",
    "job_vectors = tfidf_matrix[len(resume_df):]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb819263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2484, 3909)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(resume_vectors, job_vectors)\n",
    "similarity_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3376ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>Data Scientist (Marketing Analytics)</td>\n",
       "      <td>Whole Foods Market\\n3.6</td>\n",
       "      <td>Austin, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>Marketing &amp; Data Analyst</td>\n",
       "      <td>Principle Auto\\n4.1</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>Quantitative Analyst</td>\n",
       "      <td>Numeric, LLC\\n3.2</td>\n",
       "      <td>Houston, TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>Data Analyst, Marketing</td>\n",
       "      <td>National Education Partners\\n4.6</td>\n",
       "      <td>Scottsdale, AZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347</th>\n",
       "      <td>Marketing Data Analyst</td>\n",
       "      <td>Show Me Leads</td>\n",
       "      <td>Austin, TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Job Title                      Company Name  \\\n",
       "3220  Data Scientist (Marketing Analytics)           Whole Foods Market\\n3.6   \n",
       "2037              Marketing & Data Analyst               Principle Auto\\n4.1   \n",
       "1077                  Quantitative Analyst                 Numeric, LLC\\n3.2   \n",
       "1330               Data Analyst, Marketing  National Education Partners\\n4.6   \n",
       "3347                Marketing Data Analyst                     Show Me Leads   \n",
       "\n",
       "             Location  \n",
       "3220       Austin, TX  \n",
       "2037  San Antonio, TX  \n",
       "1077      Houston, TX  \n",
       "1330   Scottsdale, AZ  \n",
       "3347       Austin, TX  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "resume_index = 0  # first resume\n",
    "top_jobs = similarity_matrix[resume_index].argsort()[-5:][::-1]\n",
    "\n",
    "job_df.iloc[top_jobs][['Job Title', 'Company Name', 'Location']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "276ab497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Match %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3220</th>\n",
       "      <td>Data Scientist (Marketing Analytics)</td>\n",
       "      <td>Whole Foods Market\\n3.6</td>\n",
       "      <td>25.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>Marketing &amp; Data Analyst</td>\n",
       "      <td>Principle Auto\\n4.1</td>\n",
       "      <td>23.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>Quantitative Analyst</td>\n",
       "      <td>Numeric, LLC\\n3.2</td>\n",
       "      <td>23.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>Data Analyst, Marketing</td>\n",
       "      <td>National Education Partners\\n4.6</td>\n",
       "      <td>21.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347</th>\n",
       "      <td>Marketing Data Analyst</td>\n",
       "      <td>Show Me Leads</td>\n",
       "      <td>20.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Job Title                      Company Name  \\\n",
       "3220  Data Scientist (Marketing Analytics)           Whole Foods Market\\n3.6   \n",
       "2037              Marketing & Data Analyst               Principle Auto\\n4.1   \n",
       "1077                  Quantitative Analyst                 Numeric, LLC\\n3.2   \n",
       "1330               Data Analyst, Marketing  National Education Partners\\n4.6   \n",
       "3347                Marketing Data Analyst                     Show Me Leads   \n",
       "\n",
       "      Match %  \n",
       "3220    25.04  \n",
       "2037    23.80  \n",
       "1077    23.46  \n",
       "1330    21.88  \n",
       "3347    20.60  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = similarity_matrix[resume_index][top_jobs] * 100\n",
    "\n",
    "result = job_df.iloc[top_jobs][['Job Title', 'Company Name']]\n",
    "result['Match %'] = scores.round(2)\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c906171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"vectors.pkl\", \"wb\") as f:\n",
    "    pickle.dump((resume_vectors, job_vectors), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180e8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
